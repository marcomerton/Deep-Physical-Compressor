# Deep Physical Compressor

Official repository for the paper:

Compressing dynamical systems via deep learning while preserving their physical structure. Marco Lepri, Davide Bacciu, Cosimo Della Santina. 2022

**TL;DR**: We integrate structure-preserving model order reduction with autoencoders to learn low-dimensional approximations of high-dimensional physical systems conserving their Hamiltonian structure.


Flat AE |  Graph AE
:------:|:--------:
<img src="/results/rdm/sys1-sim23.gif" alt="simulation AE" width="350"/>  | <img src="/results/rdm/sys3-sim23.gif" alt="simulation GAE" width="350"/>

You can find the results discussed in the paper, as well as additional results, in this repository in the `/results` folder.\
In particular, videos of the simulations can be found in the compressed archives for each individual system. Results on the latent state analysis are instead located in the `./latent-analysys` subfolder.



## How to use the code

Before using the code, make sure to have MATLAB & Simulink installed, as well as a recent python version. `Pytorch` and `torch_geometric` are also required to run the model training.\
With conda, you can install both using
```
conda install pyg -c pyg
```
or see the [official documentation](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html) for more details.



### Data Collection
The `/matlab` folder contains all the required code to collect the training and test data.

To collect the training data, open MATLAB, move to the `/matlab` folder and execute the `./gather_training_data.m` script. This generates a `/data` folder with one subfolder for each system (e.g. `/data/sys1/`) containing the mass-spring model informations and the simulations data.\
Once the data is collected, this is ready to use for the models training (see below).

To collect the test data, first you need to collect the training data. Once that is done, open MATLAB, move to the `/matlab` folder and execute the `./gather_training_data.m` script. This generates a `/results` folder with one subfolder for each system (e.g. `/results/sys1/`) containing the dats for each simulation.



### Models Training
To train a model on the collected data, execute the `./train_model.py` script.
```
python train_model.py [-s SEED] config_file datatset filename
```
It takes the following parameters:
- `config_file`: a json configuration file specifying the (hyper)parameters of the models. Note that the name of the parameters must match the name of the argumants taken by the relative model constructor. You can find example model configuration files in the `/configs` folder.
- `dataset`: the name of the dataset to train the model on, e.g. `sys1`. Note that this must be equal to a subfolder in the `/data` directory.
- `filename`: name of the file where the model parameters are saved. This is also the prefix for the files containing the learning curves.
- `seed`: an optional seed for the RNG


Similarly, to perform a grid search, execute the `./grid_search.py` script.
```
python grid_search.py [-s SEED] config_file dataset save_prefix
```
In this case, the configuration file requires a `grid_search` field where the names of the hyperparameters are specified. Those must correspond to fields in the configuration file where multiple values are provided (e.g. a list of learning rates). `save_prefix` is instead the prefix for the files generated by the grid search. These include the learning curves for each model (files `${I}_tr` and `${I}_vl`) and the summary.

**Note**: the `/results` folder already contains the grid search results and final models for the five systems considered in the paper.



### Compressed Simulations
...
